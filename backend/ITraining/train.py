import os
import sys
import yaml
import argparse
from ultralytics import YOLO
from config import get_tasks_path, get_models_path
import os
import time
import requests
from tqdm import tqdm

def load_task_config(task_file):
    """
    åŠ è½½ä»»åŠ¡é…ç½®
    """
    if not os.path.exists(task_file):
        print(f"[ERROR] é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {task_file}")
        sys.exit(1)
    with open(task_file, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    return config

def load_platform_infofile(dataset_path):
    """
    åŠ è½½å¹³å°æ•°æ®é›†é…ç½®
    """
    dataset_platforminfofile_path = os.path.join(dataset_path, "yolo_training_visualization_info.yaml")
    if not os.path.exists(dataset_platforminfofile_path):
        print(f"[ERROR] æ•°æ®é›†å¹³å°é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {dataset_platforminfofile_path}")
        sys.exit(1) 
        
    with open(dataset_platforminfofile_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    return config

def download_model(model_name, model_browser_download_url):
    """
    æ ¹æ® baseModelInfo ä¸‹è½½æ¨¡å‹ï¼Œå¸¦è¿›åº¦æ¡
    """
    download_dir = os.path.join(get_models_path(), "base")
    
    os.makedirs(download_dir, exist_ok=True)
    local_path = os.path.join(download_dir, model_name)
    
    if not os.path.exists(local_path):
        print(f"[INFO] æ­£åœ¨ä¸‹è½½æ¨¡å‹: {model_name}")
        
        with requests.get(model_browser_download_url, stream=True) as r:
            r.raise_for_status()
            total_size = int(r.headers.get('content-length', 0))
            block_size = 1024

            with open(local_path, 'wb') as f, tqdm(
                desc=model_name,
                total=total_size,
                unit='iB',
                unit_scale=True,
                unit_divisor=1024
            ) as bar:
                for chunk in r.iter_content(chunk_size=block_size):
                    if chunk:
                        f.write(chunk)
                        bar.update(len(chunk))
        
        print(f"[INFO] ä¸‹è½½å®Œæˆ: {local_path}")
    else:
        print(f"[INFO] æ¨¡å‹å·²å­˜åœ¨: {local_path}")
    
    return local_path

def main(taskfile_path):
    tasks_dir = get_tasks_path()
    task_file = os.path.join(tasks_dir, taskfile_path)

    config = load_task_config(task_file)

    print(f"[INFO] åŠ è½½é…ç½®æˆåŠŸ: {taskfile_path}")
    print(f"[INFO] é…ç½®å†…å®¹: {yaml.dump(config, allow_unicode=True)}")

    dataset_path = config['datasetPath']
    epochs = config.get('epochs', 100)
    batch_size = config.get('batchSize', 16)
    imgsz = config.get('imgSize', 640)
    seed = config.get('trainSeed', 0)
    cache = config.get('cache', 'disk')
    training_type = config.get('trainingType', 0)
    
    platform_infofile = load_platform_infofile(dataset_path)
    dataset_yamlfile = platform_infofile.get('yaml_file_path', None)
    if dataset_yamlfile == None:
        print(f"[ERROR] æ•°æ®é›†å¹³å°é…ç½®æ–‡ä»¶ä¿¡æ¯ç¼ºå¤±: æ‰¾ä¸åˆ°æ•°æ®é›†Yamlé…ç½®æ–‡ä»¶")
        sys.exit(1) 
    
    dataset_yamlfile_path = os.path.join(dataset_path, dataset_yamlfile)
    
    extra_params = {}
    match training_type:
        case 0:
            extra_params['base_model_info'] = config.get('baseModelInfo', None)
            if extra_params['base_model_info'] == None:
                print(f"[ERROR] åŠ è½½åŸºç¡€æ¨¡å‹é…ç½®æ—¶å‡ºé”™")
                sys.exit(1) 
        case 1:
            extra_params['modelYamlFile'] = config.get('modelYamlFile', None)
            if extra_params['modelYamlFile'] == None:
                print(f"[ERROR] åŠ è½½æ¨¡å‹ç»“æ„Yamlæ–‡ä»¶é…ç½®æ—¶å‡ºé”™")
                sys.exit(1) 
        case _:
            print(f"[ERROR] è®­ç»ƒç±»å‹æ— æ•ˆ(0,1)")
            sys.exit(1) 
    
    device = config.get('device', 0)
    device_params = {"device": device}
    match device:
        case "gpu":
            device_params["gpuCUDAIndex"] = config.get("gpuCUDAIndex", "0")
        case "gpu_idlefirst":
            device_params["gpuCUDANum"] = int(config.get("gpuCUDANum", 1))
        case _:
            pass
        
    match training_type:
        case 0:
            try:
                model_name = extra_params['base_model_info']['name']
                model_browser_download_url = extra_params['base_model_info']['browser_download_url']
                model_path = os.path.join(get_models_path(), "base", model_name)
                if not os.path.exists(model_path):
                    download_model(model_name, model_browser_download_url)
            except:
                print(f"[ERROR] ä¸‹è½½æ¨¡å‹æ—¶å‡ºé”™")
                sys.exit(1) 
        case 1:
            try:
                yaml_file = config.get('modelYamlFile')
                
                tmp_yaml = f"tmp_{int(time.time())}.yaml"
                with open(tmp_yaml, 'w', encoding='utf-8') as f:
                    f.write(yaml_file)
                    
                model_path = tmp_yaml
            except:
                print(f"[ERROR] åœ¨æœ¬åœ°ç”Ÿæˆä¸´æ—¶Yamlæ–‡ä»¶æ—¶å‡ºé”™")
                sys.exit(1) 
            
    print(f"[INFO] å¼€å§‹è®­ç»ƒæ¨¡å‹...")
    model = YOLO(model_path)
    
    match device:
        case "gpu":
            device_arg = device_params["gpuCUDAIndex"].split(",")
        case "gpu_idlefirst":
            device_arg = []
            for _ in range(device_params["gpuCUDANum"]):
                device_arg.append(-1)
        case "mps":
            device_arg = "mps"
        case _:
            device_arg = "cpu"
    
    project_path = os.path.join(get_tasks_path(), "training", f"task_{int(time.time())}")
    if cache == "disk":
        _cache = False
    else:
        _cache = True
    
    model.train(
        data=dataset_yamlfile_path,
        project=project_path,
        name="result",
        epochs=int(epochs),
        batch=int(batch_size),
        imgsz=int(imgsz),
        seed=int(seed),
        cache=_cache,
        device=device_arg,
        plots=True,
        save_period=5
    )
    
    print("[INFO] ğŸ‰ è®­ç»ƒå®Œæˆ")
